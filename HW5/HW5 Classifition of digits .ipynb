{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6566c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.io.fits as pf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from skimage.transform import rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ea8bbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_me_Pytorch_data_form(input_image, input_labels,torch_format=True):\n",
    "    whole_length = len(input_image[0])\n",
    "    width = int(np.sqrt(whole_length))\n",
    "    image_matrix = np.zeros((len(input_image),1,width,width))\n",
    "    labels_matrix = np.zeros((len(input_image),10))\n",
    "    for i in range(0,len(input_image)):\n",
    "        image_matrix[i,0,:,:]=input_image[i].reshape(width,width)\n",
    "        labels_matrix[i,input_labels[i]]=1.\n",
    "    \n",
    "    if torch_format==True:\n",
    "        image_matrix = torch.from_numpy(np.array(image_matrix,dtype=np.float32))\n",
    "        labels_matrix = torch.from_numpy(np.array(labels_matrix,dtype=np.float32))\n",
    "\n",
    "    return image_matrix,labels_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae0a953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pf.open('Training.fits')\n",
    "test = pf.open('Test.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06abc46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train, image_labels = give_me_Pytorch_data_form(train[0].data,train[1].data,torch_format=True)\n",
    "image_test, test_labels = give_me_Pytorch_data_form(test[0].data,test[1].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "15fa7bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        ### \n",
    "        ### input 1x8x8 \n",
    "        self.cnn1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=1, out_channels=8,kernel_size=3,padding=1,stride=1), #8x8x8\n",
    "            torch.nn.BatchNorm2d(8),\n",
    "            #torch.nn.MaxPool2d(kernel_size=2), #20x4x4\n",
    "            torch.nn.ReLU(),\n",
    "            )\n",
    "        self.cnn2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=8, out_channels=8,kernel_size=3,padding=1,stride=1),#8x8x8 \n",
    "            torch.nn.BatchNorm2d(8),\n",
    "            #torch.nn.MaxPool2d(kernel_size=2), #20x4x4\n",
    "            torch.nn.ReLU(),\n",
    "        \n",
    "        )\n",
    "        self.cnn3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=8, out_channels=8,kernel_size=3,padding=1,stride=1),#8x9x9 \n",
    "            torch.nn.BatchNorm2d(8),\n",
    "            #torch.nn.MaxPool2d(kernel_size=2), #20x4x4\n",
    "            torch.nn.ReLU(),\n",
    "        \n",
    "        )\n",
    "        self.cnn4 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=8, out_channels=8,kernel_size=3,padding=1,stride=1),#8x8x8 \n",
    "            torch.nn.BatchNorm2d(8),\n",
    "            #torch.nn.MaxPool2d(kernel_size=2), #20x4x4\n",
    "            torch.nn.ReLU(),\n",
    "        \n",
    "        )\n",
    "        \n",
    "        self.fc1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(648, 300)\n",
    "           )\n",
    "        self.fc2 = torch.nn.Sequential(\n",
    "             torch.nn.Linear(300, 150)\n",
    "           )\n",
    "        self.fc3 = torch.nn.Sequential(\n",
    "             torch.nn.Linear(150, 10)\n",
    "           )\n",
    "              \n",
    "        #self.fc2 = torch.nn.Linear(10, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.cnn1(x)\n",
    "        x = self.cnn2(x)\n",
    "        x = self.cnn3(x)\n",
    "        x = self.cnn4(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x) \n",
    "    \n",
    "        out = x\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7919097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "479a22c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRate = 0.01\n",
    "epochs = 100\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# Just the loss function : here we use the default CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8d3d5153",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x800 and 648x300)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n0/3y7lpqp53zx9s1kwpjwh42l00000gn/T/ipykernel_81007/3758453114.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# get output from the model, given the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#print(len(color_train[start_index_batch:end_index,:]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_index_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# get loss for the predicted output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/n0/3y7lpqp53zx9s1kwpjwh42l00000gn/T/ipykernel_81007/3594777675.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x800 and 648x300)"
     ]
    }
   ],
   "source": [
    "accuracy_array = []\n",
    "accuracy_test_array = []\n",
    "loss_array = []\n",
    "loss_test_array = []\n",
    "epoch_array = []\n",
    "N_total_train = len(image_train)\n",
    "batch_size=64\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    model.train() # here is to tell the code to do the training again after model.eval() mode\n",
    "    # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
    "    for start_index_batch in range(0,N_total_train,batch_size):\n",
    "        # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
    "        optimizer.zero_grad()\n",
    "        end_index = min(start_index_batch + batch_size, N_total_train)\n",
    "        # get output from the model, given the inputs\n",
    "        #print(len(color_train[start_index_batch:end_index,:]))\n",
    "        outputs = model(image_train[start_index_batch:end_index])\n",
    "        \n",
    "        # get loss for the predicted output\n",
    "        loss = criterion(outputs, image_labels[start_index_batch:end_index,:])\n",
    "        # get gradients w.r.t to parameters\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.eval() # here is to fix the parameters (mean, sigma) of the batchnormalization, given that the batchnorm calculates the mean sigma with a new batch everytime during training. \n",
    "    with torch.no_grad():   \n",
    "        outputs_all = model(image_train)\n",
    "        pred_y = torch.max(outputs_all, 1)[1].data.squeeze()\n",
    "        accuracy = torch.sum((pred_y == torch.max(image_labels, 1)[1].data.squeeze()) / pred_y.size(0))\n",
    "        epoch_array.append(epoch)\n",
    "\n",
    "        loss_array.append(float(loss.detach().numpy()))\n",
    "        accuracy_array.append(float(accuracy.numpy()))\n",
    "\n",
    "\n",
    "        outputs_test = model(image_test) \n",
    "        loss_test = criterion(outputs_test, test_labels)\n",
    "\n",
    "        pred_y_test = torch.max(outputs_test, 1)[1].data.squeeze()\n",
    "        accuracy_test = torch.sum((pred_y_test == torch.max(test_labels, 1)[1].data.squeeze()) / pred_y_test.size(0))\n",
    "        accuracy_test_array.append(float(accuracy_test.numpy()))\n",
    "        loss_test_array.append(float(loss_test.detach().numpy()))\n",
    "\n",
    "    if epoch % 1 ==0:\n",
    "        print(epoch,accuracy.numpy(),loss.detach().numpy(), accuracy_test.numpy(),loss_test.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5254e87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x145fa31c0>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(epoch_array,accuracy_array,color='C0')\n",
    "plt.scatter(epoch_array,accuracy_test_array,color='C1')\n",
    "plt.ylim(0.95,1.01)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.axhline(0.9912,ls='--',color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b075a453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820949bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
